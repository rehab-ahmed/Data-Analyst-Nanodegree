{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chosen Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Location: Cairo, Egypt\n",
    "* Data: https://s3.amazonaws.com/metro-extracts.mapzen.com/cairo_egypt.osm.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as cET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "import collections\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import string\n",
    "from pymongo import MongoClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "datadir = \"data\"\n",
    "datafile = \"cairo_egypt.osm\"\n",
    "cairo_data = os.path.join(datadir, datafile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 964,\n",
      " 'nd': 720267,\n",
      " 'node': 553028,\n",
      " 'osm': 1,\n",
      " 'relation': 221,\n",
      " 'tag': 253248,\n",
      " 'way': 112845}\n"
     ]
    }
   ],
   "source": [
    "#Parse through the file with ElementTree and count the number of unique element types to understand overall structure.\n",
    "def count_tags(filename):\n",
    "        tags = {}\n",
    "        for event, elem in cET.iterparse(filename):\n",
    "            if elem.tag in tags: \n",
    "                tags[elem.tag] += 1\n",
    "            else:\n",
    "                tags[elem.tag] = 1\n",
    "        return tags\n",
    "cairo_tags = count_tags(cairo_data)\n",
    "pprint.pprint(cairo_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "931"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#people invovlved in the map editing.\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in cET.iterparse(filename):\n",
    "        for e in element:\n",
    "            if 'uid' in e.attrib:\n",
    "                users.add(e.attrib['uid'])\n",
    "    return users\n",
    "users = process_map(cairo_data)\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problems Encountered in the Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's explore the street names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "common_street_names = [\"Street\", \"Road\", \"District\"]\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in common_street_names:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in cET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Al-Bakry set(['Al-Sayed Al-Bakry'])\n",
      "Al-Haram set(['Al-Haram'])\n",
      "Al-Hussein set(['Haret Al-Hussein'])\n",
      "Al-Mansureya set(['Tariq Al-Mansureya'])\n",
      "Al-Markazi set(['Al-Mehwar Al-Markazi'])\n",
      "Al-Roda set(['Qalaat Al-Roda'])\n",
      "Al-Sanhoory set(['Dr. Abdel Raziq Al-Sanhoory'])\n",
      "Al-Sherif set(['Al-Quds Al-Sherif'])\n",
      "Al-Zaheri set(['Abu Dawoud Al-Zaheri'])\n",
      "Awad set(['Dr. Mohamed Awad'])\n"
     ]
    }
   ],
   "source": [
    "cairo_street_types = audit(cairo_data)\n",
    "for key in sorted(dict(cairo_street_types))[30:40]:\n",
    "    print key, dict(cairo_street_types)[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems that the data for street names is too messy to be fixed. There is huge inconsistency and no certain format is followed when the address is added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * What about the postal codes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def audit_zipcode(invalid_zipcodes, zipcode):\n",
    "    twoDigits = zipcode[0:2]\n",
    "    \n",
    "    if not twoDigits.isdigit():\n",
    "        invalid_zipcodes[twoDigits].add(zipcode)\n",
    "    \n",
    "    elif twoDigits != 95:\n",
    "        invalid_zipcodes[twoDigits].add(zipcode)\n",
    "        \n",
    "def is_zipcode(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def audit_zip(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    invalid_zipcodes = defaultdict(set)\n",
    "    for event, elem in cET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_zipcode(tag):\n",
    "                    audit_zipcode(invalid_zipcodes,tag.attrib['v'])\n",
    "\n",
    "    return invalid_zipcodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 set(['002'])\n",
      "01 set(['01066047247'])\n",
      "11 set(['11511', '11321', '11221', '11774', '11381', '11111', '11241', '11361', '11811', '11421', '11865', '11835', '11551', '11211', '11936', '11231', '11311', '11351', '11371', '11759', '11451', '11476', '11737', '11717', '11431', '11517'])\n",
      "12 set(['12111', '12519', '12577', '12561', '12573', '12516', '12510', '12511', '12512', '12566', '12411', '12555', '12541', '12311', '12513', '12344'])\n",
      "19 set(['19511'])\n",
      "24 set(['2466'])\n",
      "25 set(['2500'])\n",
      "31 set(['31'])\n",
      "56 set(['560037'])\n",
      "76 set(['7608'])\n"
     ]
    }
   ],
   "source": [
    "cairo_zipcode = audit_zip(cairo_data)\n",
    "for key in sorted(dict(cairo_zipcode))[:10]:\n",
    "    print key, dict(cairo_zipcode)[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many zip codes are incorrect and inconsistent. There is even a phone number in the data. So let's try to clean the data and only keep the correct postal codes.\n",
    "### The correct postal code in cairo consists of 5 numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11511 => 11511\n",
      "11321 => 11321\n",
      "11221 => 11221\n",
      "11774 => 11774\n",
      "11381 => 11381\n",
      "11111 => 11111\n",
      "11241 => 11241\n",
      "11361 => 11361\n",
      "11811 => 11811\n",
      "11421 => 11421\n",
      "11865 => 11865\n",
      "11835 => 11835\n",
      "11551 => 11551\n",
      "11211 => 11211\n",
      "11936 => 11936\n",
      "11231 => 11231\n",
      "11311 => 11311\n",
      "11351 => 11351\n",
      "11371 => 11371\n",
      "11759 => 11759\n",
      "11451 => 11451\n",
      "11476 => 11476\n",
      "11737 => 11737\n",
      "11717 => 11717\n",
      "11431 => 11431\n",
      "11517 => 11517\n",
      "2500 => N/A\n",
      "002 => N/A\n",
      "12111 => 12111\n",
      "12519 => 12519\n",
      "12577 => 12577\n",
      "12561 => 12561\n",
      "12573 => 12573\n",
      "12516 => 12516\n",
      "12510 => 12510\n",
      "12511 => 12511\n",
      "12512 => 12512\n",
      "12566 => 12566\n",
      "12411 => 12411\n",
      "12555 => 12555\n",
      "12541 => 12541\n",
      "12311 => 12311\n",
      "12513 => 12513\n",
      "12344 => 12344\n",
      "None => N/A\n",
      "19511 => 19511\n",
      "31 => N/A\n",
      "560037 => N/A\n",
      "7608 => N/A\n",
      "01066047247 => N/A\n",
      "2466 => N/A\n",
      "شارع أحمد فهيم بيومي => N/A\n"
     ]
    }
   ],
   "source": [
    "postcode_matching = re.compile(\"^\\d{5}$\")\n",
    "\n",
    "def audit_zipcode(invalid_zipcodes, zipcode):\n",
    "    twoDigits = zipcode[0:2]\n",
    "    \n",
    "    if not twoDigits.isdigit():\n",
    "        invalid_zipcodes[twoDigits].add(zipcode)\n",
    "    \n",
    "    elif twoDigits != 95:\n",
    "        invalid_zipcodes[twoDigits].add(zipcode)\n",
    "        \n",
    "def is_zipcode(elem):\n",
    "    return (elem.attrib['k'] == \"addr:postcode\")\n",
    "\n",
    "def audit_zip(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    invalid_zipcodes = defaultdict(set)\n",
    "    for event, elem in cET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_zipcode(tag):\n",
    "                    audit_zipcode(invalid_zipcodes,tag.attrib['v'])\n",
    "\n",
    "    return invalid_zipcodes\n",
    "cairo_zipcode = audit_zip(cairo_data)\n",
    "for street_type, ways in cairo_zipcode.iteritems():\n",
    "    for name in ways:\n",
    "        if (postcode_matching.match(name)):\n",
    "            better_name = name\n",
    "        else: \n",
    "            better_name= \"N/A\"\n",
    "        print name, \"=>\", better_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the XML into JSON format for mongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    node[\"created\"]={}\n",
    "    node[\"address\"]={}\n",
    "    node[\"pos\"]=[]\n",
    "    refs=[]\n",
    "    \n",
    "    # we only process the node and way tags\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        if \"id\" in element.attrib:\n",
    "            node[\"id\"]=element.attrib[\"id\"]\n",
    "        node[\"type\"]=element.tag\n",
    "\n",
    "        if \"visible\" in element.attrib.keys():\n",
    "            node[\"visible\"]=element.attrib[\"visible\"]\n",
    "      \n",
    "        # the key-value pairs with attributes in the CREATED list are added under key \"created\"\n",
    "        for elem in CREATED:\n",
    "            if elem in element.attrib:\n",
    "                node[\"created\"][elem]=element.attrib[elem]\n",
    "                \n",
    "        # attributes for latitude and longitude are added to a \"pos\" array\n",
    "        # include latitude value        \n",
    "        if \"lat\" in element.attrib:\n",
    "            node[\"pos\"].append(float(element.attrib[\"lat\"]))\n",
    "        # include longitude value    \n",
    "        if \"lon\" in element.attrib:\n",
    "            node[\"pos\"].append(float(element.attrib[\"lon\"]))\n",
    "\n",
    "        \n",
    "        for tag in element.iter(\"tag\"):\n",
    "            if not(problemchars.search(tag.attrib['k'])):\n",
    "                if tag.attrib['k'] == \"addr:housenumber\":\n",
    "                    node[\"address\"][\"housenumber\"]=tag.attrib['v']\n",
    "                    \n",
    "                if tag.attrib['k'] == \"addr:postcode\":\n",
    "                    node[\"address\"][\"postcode\"]=tag.attrib['v']\n",
    "                \n",
    "                if tag.attrib['k'] == \"addr:street\":\n",
    "                    node[\"address\"][\"street\"]=tag.attrib['v']\n",
    "                    node[\"address\"][\"street\"] = node[\"address\"][\"street\"]\n",
    "\n",
    "                \n",
    "                if tag.attrib['k'].find(\"addr\")==-1:\n",
    "                    node[tag.attrib['k']]=tag.attrib['v']\n",
    "                    \n",
    "        for nd in element.iter(\"nd\"):\n",
    "             refs.append(nd.attrib[\"ref\"])\n",
    "                \n",
    "        if node[\"address\"] =={}:\n",
    "            node.pop(\"address\", None)\n",
    "\n",
    "        if refs != []:\n",
    "           node[\"node_refs\"]=refs\n",
    "            \n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# process the xml openstreetmap file, write a json out file and return a list of dictionaries\n",
    "def process_map(file_in, pretty = False):\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in cET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process the file\n",
    "data = process_map(cairo_data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x5e8ff8b8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "db = client.CairoOSM\n",
    "collection = db.cairoMAP\n",
    "collection.insert_many(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The xml file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121L"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(cairo_data)/1024/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The JSON file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190L"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.getsize(os.path.join(datadir, \"cairo_egypt.osm.json\"))/1024/1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Number of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2663492"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.find().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Number of Unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "925"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(collection.group([\"created.uid\"], {}, {\"count\":0}, \"function(o, p){p.count++}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Number of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2212092"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.find({\"type\":\"node\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Number of Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451364"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.find({\"type\":\"way\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 users with most contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': 444824, u'_id': u'Salmanjk'}, {u'count': 247396, u'_id': u'Mohawow'}, {u'count': 241584, u'_id': u'warneke7'}, {u'count': 187992, u'_id': u'Triscia'}, {u'count': 149512, u'_id': u'Allegro34'}]\n"
     ]
    }
   ],
   "source": [
    "pipeline = [{\"$group\":{\"_id\": \"$created.user\",\n",
    "                       \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}},\n",
    "            {\"$limit\": 5}]\n",
    "result = collection.aggregate(pipeline)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Proportion of the top user contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'Salmanjk', u'proportion': 0.16700782281305895}, {u'_id': u'Mohawow', u'proportion': 0.09288407849544883}, {u'_id': u'warneke7', u'proportion': 0.09070198070803291}, {u'_id': u'Triscia', u'proportion': 0.070581026712301}, {u'_id': u'Allegro34', u'proportion': 0.05613382732142616}]\n"
     ]
    }
   ],
   "source": [
    "pipeline = [{\"$group\":{\"_id\": \"$created.user\",\n",
    "                       \"count\": {\"$sum\": 1}}},\n",
    "            {\"$project\": {\"proportion\": {\"$divide\" :[\"$count\",collection.find().count()]}}},\n",
    "            {\"$sort\": {\"proportion\": -1}},\n",
    "            {\"$limit\": 5}]\n",
    "result = collection.aggregate(pipeline)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most popular cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': 76, u'_id': u'regional'}, {u'count': 40, u'_id': u'italian'}, {u'count': 28, u'_id': u'chicken'}, {u'count': 28, u'_id': u'pizza'}, {u'count': 28, u'_id': u'american'}, {u'count': 24, u'_id': u'burger'}, {u'count': 16, u'_id': u'kebab'}, {u'count': 16, u'_id': u'chinese'}, {u'count': 16, u'_id': u'ice_cream'}, {u'count': 12, u'_id': u'asian'}]\n"
     ]
    }
   ],
   "source": [
    "pipeline = [{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\":\"restaurant\", \"cuisine\":{\"$exists\":1}}}, \n",
    "            {\"$group\":{\"_id\":\"$cuisine\", \"count\":{\"$sum\":1}}},        \n",
    "            {\"$sort\":{\"count\":-1}}, \n",
    "            {\"$limit\":10}]\n",
    "result = collection.aggregate(pipeline)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of universities in Cairo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = [{\"$match\":{\"amenity\":{\"$exists\":1}, \"amenity\": \"university\", \"name\":{\"$exists\":1}}},\n",
    "            {\"$group\":{\"_id\":\"$name\", \"count\":{\"$sum\":1}}},\n",
    "            {\"$sort\":{\"count\":-1}}]\n",
    "result = collection.aggregate(pipeline)\n",
    "len(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This number is way more than the number of universities in Cairo. Some faculties were entered as universities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 common amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'count': 1896, u'_id': u'place_of_worship'}, {u'count': 1520, u'_id': u'parking'}, {u'count': 980, u'_id': u'restaurant'}, {u'count': 820, u'_id': u'school'}, {u'count': 764, u'_id': u'cafe'}]\n"
     ]
    }
   ],
   "source": [
    "pipeline = [{\"$match\":{\"amenity\":{\"$exists\":1}}},\n",
    "            {\"$group\":{\"_id\":\"$amenity\", \"count\":{\"$sum\":1}}},\n",
    "            {\"$sort\":{\"count\":-1}},\n",
    "             {\"$limit\":5}]\n",
    "result = collection.aggregate(pipeline)\n",
    "print(list(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* The data for Cairo, Egypt is messy, inconsistent and incomplete. Some features cannot even be repaired or processed.\n",
    "* Most citizens do not know the postal code or even its correct format. From personal experience, I did not know my zip code till recently when I needed it.\n",
    "* There is no address convention and the same address an be written in many ways (even in official papers).\n",
    "* Some data are entered in different language (Arabic) specially when it is difficult to write the street name in English."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas for improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The data should be verified, e.x: The zip code should consist of 5 numbers.\n",
    "* The address could be distributed to many sub-fields (governorate, street, building no,..etc) to have consistent format and facilitate data cleaning and processing.\n",
    "* A sample entry for each field will help users understand the required data for this field. Some users entered phone numbers in the zipcode field.\n",
    "* Drop-down menus for the area names would improve the data quality. This idea is already implemented in some online food services.\n",
    "* There is a census being repaired now in Egypt and the governmental data could be used which would be more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some challenges with applyng the ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The language is a huge obstacle. Many Egyptians do not speak English and many will always find it easier to add the data in Arabic.\n",
    "* Adding a predefined set in a dropmenu could cause a problem because street names are changes so oftenand the list should be updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://mapzen.com/data/metro-extracts/\n",
    "* https://www.openstreetmap.org/#map=10/30.0346/31.5651   "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
